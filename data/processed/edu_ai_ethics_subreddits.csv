subreddit,title,selftext,score,created_utc,url
Professors,# --- Search Parameters ---,"I'm working on a white paper for my uni about the risks faced by a university by increasing use by students of GenAI tools.   

The basic dynamic that is often lamented on this subreddit is :  (1) students relying increasingly upon AI for their evaluated work, and (2) thus not actually learning the content of their courses,  and (3) faculty and universities not having good ways to respond.   

Unfortunately Turnitin and document tracking software are not really up to the job  (too high false positive and false negative rates).    

I see lots or university teaching centers recommending that faculty ""engage"" and ""communicate"" with students about proper use and avoiding misuse of GenAI tools.   I suppose that might help in small classes where you can really talk with students and where peer pressure among students might kick in.  Its hard to see it working for large classes.  

So this leaves redesigning courses to prevent misuse of GenAI tools - i.e. basically not having them do much work outside of supervision.    

I see lots of references by folks on here to not be allowed to deny students use of GenAI tools outside of class or other references to a lack of support for preventing student misuse of GenAI tools.  

I'd be eager to hear of any actual specific policies along these lines - i.e. policies that prevent improving courses and student learning by reducing the abuse of GenAI tools.    (feel free to message me if that helps)

thanks",11,1753135779,https://www.reddit.com/r/Professors/comments/1m5wmrh/prevented_from_prohibiting_chatgpt/
Professors,"query = ""AI makes students lazy""","I’m struggling with the tension between promoting equity and maintaining academic integrity. I wholeheartedly support inclusive, student-centered education. But in practice, I see widespread academic dishonesty such as AI misuse, ghostwriting, and test cheating, with little appetite from institutions to address it meaningfully.

At times, it feels like the push for equity is being selectively applied or even used to excuse misconduct. Are we unintentionally enabling bad actors while disadvantaging the honest students we are trying to uplift?

Meanwhile, institutions keep broadcasting their commitment to rigor and ethics. But what are we really doing? Are we creating equitable learning environments, or just staging a performance while quietly letting the system rot?

Are we helping students succeed, or just lowering the bar while pretending everything is fine? I’m starting to feel like the whole thing is more about optics than outcomes. More about international enrollment than education. 

Curious if anyone else sees this, or if I’m just getting cynical.

",164,1749684054,https://www.reddit.com/r/Professors/comments/1l97dc6/how_do_you_reconcile_equity_and_social_justice/
Professors,"subreddits = [""education"", ""ChatGPT"", ""Professors"", ""college""]","Hello All:

Hopefully you’re surviving the end of the term. Grading will be done before we know it. Hallelujah! :) 

So yesterday my night class wrapped up their final class. I am an online adjunct professor who teaches intercultural communication via Zoom. So my students did their final group speeches. All groups and their group members attended and did great. 

Well there was one group member from one of the groups who has been a pain in the rear all semester long. He has skipped quite a few classes and hasn’t really done anything all term.  Yes, he isn’t doing great at all, you guessed it! His group informed me several times via email and also when I did check ins during class work time in breakout rooms that this member didn’t do a darn thing and never contributed at all. There were times when he skipped when I offered group time during class time. In the few times that he was in class he refused to work in his group even after I told him several times he needed to. 

As you guessed it, he skipped class yesterday and didn’t do his group speech with his group. Me and his group members never heard from him. Yes, this is an automatic 0 since he never told me of his absence nor provided any documentation as required in my course polices. 

This afternoon I got an email on his school email account from supposedly his girlfriend telling me he missed class last night because he is bedridden with COVID. She wanted to know how this would affect his grade and what he should do next. She also told me she contacted his group members too. Oh I am sure they were just as suspicious as I was when I read her email. 

You know what’s funny. He was on our LMS in the morning both today and yesterday submitting assignments he hadn’t done. 

I emailed my department chair to get her in on this. I sent her all my communications that he never responded to and all the evidence I could provide including the evidence that his group provided showing no contribution on his end. She told me to tell the girlfriend that I can’t discuss his situation with her as that would be a violation of FERPA and to have the student contact me directly. My chair also pointed out how this is definitely a misuse of email which is clearly a violation I would imagine at any college. She also told me to go ahead and give the student a 0 per my policy in the syllabus. 

What concerns me is how he couldn’t communicate with me all semester and had his girlfriend do it for him and he couldn’t do it himself. It looks like he panicked when it finally dawned on him that he may fail the course. Well hopefully that will teach him to communicate if he retakes it but will he. There have been so many fraud issues going around that I certainly hope this isn’t a fraud case where he is having his girlfriend do the course for him but you never know nowadays with AI and all. 

I am a little worried about getting an email back. It has been a few hours and nothing yet but I am worried about what will happen next. My department chair told me to contact her if I get a response since she is questioning if it would be him or not if I were to get a response back. 

Have you ever had a situation where someone other than the student emailed you. What did you do and how did the situation go? 

Thanks all for any input or advice, I am just hoping I handled this correctly! 

",24,1746838594,https://www.reddit.com/r/Professors/comments/1kiy4vs/have_you_ever_received_an_email_on_a_students/
Professors,limit = 50,"If you haven't heard, Alex [Shieh](https://www.browndailyherald.com/article/2025/04/university-investigating-student-who-sent-doge-style-emails-to-administrators) is a student at Brown who is currently under a disciplinary review for causing emotional and psychological harm, misusing data, and falsely claiming to be a journalist. I suspect this sub will automatically dismiss him because he is an undergrad, used AI, is brash, likes the idea of DOGE removing inefficient and wasteful positions, has been interviewed by FoxNews, is Asian, dislikes DEI, and intentionally challenges the university structure.

However, the curious aspect is that he is targeting administirative bloat with his 'investigation,' specifically positions that we on this sub have often complained about for years and years. While he indelivately lumps positions into what he classifies as DEI/woke, he also uses the term ""bullshit jobs"" which we have discussed here too.  He also specifically does NOT target students or faculty but deanlets and administrators with complicated titles that we have made fun of here. I am NOT saying he is 100% correct, but I am saying he is making arguments we have made here for a decade about the ongoing administrative expenditures having priority over things like faculty salary and facility maintenance. His concerns appear to have arisen from working in a flooded room while bserving a 50% increase in tuition over the past decade.

While his language is unrefined (as one might expect from an undergrad, even at an Ivy), I am not a big fan of the univeristy repsonse to him either. From various sources, he seems to have asked in his emails what is your job description or what do you actually do (without making a call for justification). We've done that here, and I know many of us have asked some administrators with a strange title what they do. But that email, perhaps because he made so many at once, is being held up as infliction of harm. The idea of misusing publicly available data seems to be a witch hunt. The charge of misrepresenting himself as a journalist goes against idea of citizen and activist journalists which have been recognized much more widely. He might be a jerk, but Brown's response seems exceedingly vindictive in tone so far.

So I am curious. He seems politically at odds with how most of this sub feels. But he does raise concerns we have raised for at least a decade. Is he a hero, a villain, a misguided kid, an unlikely ally, or something different?

***EDIT****: This sub is very negative, but I found a related discussion on another sub where the following quote was one of the highest-rated comments. I wish we could not be so petty and condescending when a topic comes up.*

>I think a conversation and thoughtful look at expenses at a university is badly needed but the approach taken by the student is not the most useful.",0,1744049713,https://www.reddit.com/r/Professors/comments/1jts4ns/how_do_we_feel_about_alex_shieh/
Professors,"Update: Thank you for the suggestions in my last post. This morning I asked my students to try to cheat with GPT using the method I created, but they all failed to get away with it.","Last week, this subreddit provided me with three feature suggestions after I posted about the website I created to monitor student writing in real-time (to ensure they're not copying/pasting from AI), AuthorDetector.com. Thanks for the recommendations, I implemented all of them:

1. An additional A.I. Detector: While my site focuses on detecting authors, someone suggested that I have the website report on AI styles of writing too. So I added it as an additional metric.

2. Security: Make it so that the PDF reports can be verified if they are tampered with (I used hashing).

3. Privacy: A statement that data won’t be misused (I don’t even track site visits).   
  
  
Finally, I was asked to report how well it worked. So I decided to test it with my class this morning. This isn't the most scientific test, but I did want to pilot the app to see if it worked.

Method:

The class was asked to answer the question once using their own writing and then a second time using AI. Students could make any prompt they want, including prompts to ""sound more natural"" or ""use language that will fool AI detectors.""

I asked the students to write about the positives/negatives about AI technology (I teach a class about the “Foundational AI Mechanics and the limitations for AGI”, so this exercise worked within its scope). All of the students wrote their answers using the AuthorDetector site.  Afterward, I anonymized and randomized the reports and gave them to my Teaching Assistant to grade. She had never used or seen the app I created before. I asked her to look at the writing styles and for odd metrics.

Finally, as a classroom, we all went through the reports to get an idea of what type of prompts were made to try to fool us.

Results:

It worked better than I anticipated.  My TA and I both caught every single time a student used GPT (I'd even be happy if it was above 80% but we got it 100% of the time). Some students prompted ChatGPT to have a very natural tone or to ""avoid AI detectors"" but were still caught. The reason is that whenever people used ChatGPT at least more than one metric monitored by AuthorDetector would look very off.

Limitations:

This was just one pilot trial to see if it worked. I'd love to hear the results if others run a similar test with their class (the site is free, I make no profit off it and don't log personal data).

Not everything is fool-proof. However, for students to beat AuthorDetector, the students would need to spend more cognitive effort cheating than to simply use their own thoughts and words. For example, students would have to method-act like an author and not only pretend to think but also make fake edits that look realistic enough without actually affecting the quality of their writing. 

While my TA did manage to catch every time students used AI, there were a few metrics that we can both gain a better eye for with practice. For example, if someone writes with a high word-per-minute, it's often an odd metric because it means the person did not stop to think about answers.

Thank you again for the help.



",331,1737659859,https://www.reddit.com/r/Professors/comments/1i8bfnk/update_thank_you_for_the_suggestions_in_my_last/
Professors,# --- Collect Posts ---,"
In one of my classes this semester I assigned lab reports and provided a template with the standard sections and instructions of what to put where. Introduction, background, methods, results, etc. I  gave them detailed feedback and did not take off points as long as they turned in a completed report, telling them to use the feedback to write a better report for their last report (a new topic, but still using the same template). Most students wrote C and D level reports that sorely lacked detail. My comments were almost always to refer to the template to see what other details needed to go into this section (basically follow instructions). I gave these students full credit and told them to carefully read all comments and use them to write a better report for the next one. 

The problem I ran into is that a few of these reports were different. By now I think I can recognize AI-generated writing. It uses a lot of commas (correctly) and words I wouldn’t expect a student to use in this context. Sure enough, these sections that look suspicious were flagged by TurnItIn as 100% AI. I know AI detectors can have false positives, but I think it is working in these instances. Most had used AI to write their summary and introduction, and then bits and pieces elsewhere.

I have a policy that students may not use AI to think or write for them. All work must be 100% their creation. Grammarly is an exception. So I took off 30% of the points and said they could resubmit a new version for a regrade and earn up to half of the points back. In my comments I stated that I noticed AI writing, and then Turnitin supported it.

I heard back from one student so far who quoted the University’s policy and threatened to appeal. The policy is updated since I last looked and is extremely soft. It also says that AI detection is not considered strong enough evidence to support an allegation of misconduct. The university will not be renewing the AI detection feature in turnitin. The policy says I should not accuse a student of using AI. Instead I should meet with them individually and be understanding and sympathetic, etc. Basically it makes it very hard to stand my ground. Fighting this will just suck the life out of me. F that.

So I am thinking my best option is to just drop it. The fact is that the writing in question lacks substance. It is D- or at best C-level work. Students that use AI to write for them will lose significant points anyway. So I will explain this to them and give the points back. I will grade their final reports the way I always have, and students who use AI will almost certainly lose a lot of points.

TL/DR: As it turns out, the AI written portions of my students’ papers lack substance and, even if graded without penalty, won’t earn them many points. It will be much better for my sanity to just grade their final papers as I normally would and not worry about AI. 

Thoughts?
",4,1733812852,https://www.reddit.com/r/Professors/comments/1havswr/not_standing_my_ground_on_ai_misuse_a_better/
Professors,posts_data = [],"The topic of AI use seems to be one that is impacting a lot of professors. Currently there is a lot of focus on a perspective where AI use is considered cheating, and needs to be caught and punished. I don't agree, both because it's infeasible to do fairly and because I think we need to evolve our teaching to embrace AI in the same way we have embraced calculators, Wikipedia, word processors, and other technologies that make working more efficient. 

This article focuses on the infeasibility of fairly detecting AI use, and why failing students based on an AI detector is bad practice:

[Accusatory AI: How a Widespread Misuse of AI Technology Is Harming Students](https://medium.com/towards-data-science/accusatory-ai-how-misuse-of-technology-is-harming-students-56ec50105fe5)

",0,1733763316,https://www.reddit.com/r/Professors/comments/1hae9mz/what_should_be_done_when_an_ai_detector_flags_a/
Professors,An idea: an updated 'trojan horse' method to catch AI use (while helping students that try),"Hello everyone,

There was, eight months ago,[ a post ](https://www.reddit.com/r/Professors/comments/1bitata/adding_a_trojan_horse_to_detect_ai/?utm_name=web3xcss)that suggested a way to catch students using AI by using a 'trojan horse', or 'blue dye', approach.

Today, there a post from a professor who found this helpful, but not making their life especially easier despite the method's merits: [https://www.reddit.com/r/Professors/comments/1gl3tm5/comment/lvs9vx0/?context=3](https://www.reddit.com/r/Professors/comments/1gl3tm5/comment/lvs9vx0/?context=3) . This was the first place I had encountered the 'trojan horse' approach, and had an idea about it that I shared with the OP about how to improve the method. They thought it may be a good improvement, and with their permission to cite this post, I am bringing this idea to its own forum of discussion.

(Edited because the initial text was tiresome to read...)

\- - - - -

***1/3 The idea of a modified trojan horse method:***

As a part of the discussion assignment's grade, students must identify an error in the prompt. The error should be noticeable and directly tied to key themes in the reading, making it clear to any student who engages with the material.

For example, take the abstract from this paper: [https://link.springer.com/article/10.1007/s10648-024-09904-y](https://link.springer.com/article/10.1007/s10648-024-09904-y) . Let us assume your students were meant to read this paper this week.

For a discussion , you may insert a 3-4 (short) sentence description setting up the prompt -- saying something about the central idea of the readings from that week, or the like. The trojan horse comes in at this step.

Include in one of these sentences which is an incorrect claim, a fantasy term, a made up word, or a misplaced/miused term that would otherwise be found in that text. Taking from the abstract above, this would work something like this:

“…when cultural resources build from students' sensorimotor dynamics… intrinsic sensorimotor behaviours may *not* be embraced as mental activity and instead are embraced by *midichlorians/ombimbiomosims/neurodivergency.*” I have italicised *not* (which was not what the paper said), as well as *midichlorians* (fantasy), *ombimbiomosims* (gibberish), and *seratonin* (a misuse of a term used in the abstract.)

I would guess that take the more subtle approach -- taking a term used in the article and using it in an incorrect way -- would be the most effective. Particularly, it may catch the more determined students, who may actually then upload the entire text to an AI to analyse which sentence makes the wrong claim in setting up the prompt, and an AI may not be sensitive enough to pick up on the nuance of the term.

\- - - - -

***2/3 Anticipated effect***

To respond to the discussion question, the students, first, have to identify what was wrong with the prompt -- which would require them to critically analyse the question. Then, they can proceed with the rest of the response. If you use a ridiculous trojan horse (i.e midichlorians/ombimbiomosims), then don't put any reminder whatsoever on the discussion prompt.

The students who did not even bother to look at the prompt and copy/pasted the generated response will be easy to identify. If you take the effort to put it incorrect claims that align closely with the text (such as the above example of using 'neurodivergence' instead of 'mental state'), then depending upon the sensitivity of the AI to consistency in term usage, those more discretely relying on the AI still may not catch an error.

Meanwhile, for those students who actually do the work, they may tacitly, subtly develop the instinct that it is valid to be critical of the question of the premises of a prompt.

\- - - - -

***3/3 Final comments***

The method above addresses some of the concerns expressed in the very first post about the 'trojan horse' method.

(1) It does not rely on colour formating, which

(i) prevents students from 'catching on' and

(ii) closes the potential professional hasard of being accused of entrapment.

(2) It does not go into territory about accessibility with visual disabilities, nor does it give instructions that neurodivergent students may interpret literally, (3) there is no way for students to 'catch on' except by, at *bare minimum* to be convincing, opening up the reading, opening up the discussion, and crossing the two on Chat GPT to identify the main theme of a text. At least, for the most lazy passable students, they will then know the central idea of an assigned text. It seems, to me, that the only thing for large groups of students to 'catch on' to is that they have to at least partilly read a text to pass...

\- - - - - -

I am depositing this in its own forum to gather ideas and feedback -- maybe we can make this a better method if we consider this together.

**Edit 1 - Community soft consensus 1:** Adding an edit from the comments below, though, if you take this method, then ensure to have included some low-stakes scaffolding to this assignment style earlier on in the semester for the class to be introduced to.

**Edit 2 - Notes from comments:** It appears that the text is not easily accessible to those from STEM fields. This may well be due to that I am not from the natural sciences. If you have questions, feel free to specify on any confusing parts. Additionally, I will note that this is not meant to be a 'future-proofed' approach nor to encourage a student vs. instructor approach -- which one comment pointed out, is indeed a poor approach to didactics. What I did intend this to do is suggest a possible method to identify the most harmful AI usage by students in a classroom right now -- those that are not actually learning anything because the vast majority of their work is AI generated, and probably the students could not name two texts from the course without a reference. 

\- - - - - - 

TL;DR: Read the *1/3* section.

",59,1730928843,https://www.reddit.com/r/Professors/comments/1gl9si6/an_idea_an_updated_trojan_horse_method_to_catch/
Professors,for sub in subreddits:,"My institution says if you dock a student points for cheating you have to file an academic misconduct report. This system works okay when you have a handful of cases. 

Sure the report is an online form, easy enough, but you also need to meet with the student individually and that takes a lot of time if it’s more than a few. If the student appeals you have to present to a committee designed to fail because the burden of proof is on the professor.

I have situations now where I have 50 or 100 students who are cheating weekly on coded projects. A few cases are classic plagiarism - copied another’s work - but now we also have misused ChatGPT and copied another students GPT’d code. We say in the syllabus and often in-class don’t use it because this is a foundations course. It’s running with scissors for you. 

Considering making the rubric on all future assignments maybe 50 points for convincing me through your use of problem solving and code that does not misuse AI/online resources. Then 50 percent for everything else. If it’s part of the rubric surely I can dock points if my checks flag the code? Would still submit academic misconduct forms for egregious cases. Students who want to argue their grade still could too, but then the burden of proof is on them and I can go back to being a teacher instead of this awful either punish everyone or no one choice currently in place. 

The issue to reiterate is that current policies were not designed for AI use and there is no middle ground more reasonable to manage available policy wise.

Think it might work? 
",7,1728020012,https://www.reddit.com/r/Professors/comments/1fvrzhe/has_anyone_tried_a_rubric_like_this_to_counter_ai/
Professors,"    for post in reddit.subreddit(sub).search(query, limit=limit):","I know this is nothing new, but I'm just so taken aback by the nerve some of these students have. I'm grading semi identical essays because no one even bothered to give it an interesting prompt.

I'm also surprised by how I'm letting this affect my mood. Right now I got so angry that I had to stop grading the entrance diagnostic exams my boss gave me as a ""newbie"" task (my university works in trimesters and we do a ""diagnostic"" of our new students' writing).

This is my first job as a professor. I love teaching and seeing how my students  grow as academic writers. I don't want to become bitter if (and when) I continue to encounter this blatant use of AI. 

Maybe I'm exaggerating. The rose colored glasses have been smashed and I needed to vent to someone since my partner, friends and family are currently asleep.

I'm upset and English isn't my first language, so sorry for any mistakes.

Edit: mistakes hehe",128,1727933165,https://www.reddit.com/r/Professors/comments/1fv0kxs/the_misuse_of_chatgpt_is_making_so_irrationally/
Professors,        posts_data.append({,"For the online student who has repeatedly turned in work that is highly suspicious for being AI generated - the situation where you *know* they have been cheating, but there's no hard proof.

How would you handle it if they later ask you for a letter of recommendation?

If you refuse the recommendation - do you explain why?

If you provide a reference - how does the student's misuse of AI content play a role, or not, in your review of the student?",25,1709845191,https://www.reddit.com/r/Professors/comments/1b958ad/letter_of_recommendation_request_for_aicheater/
Professors,"subreddit"": sub,
            ""title"": post.title,
            ""selftext"": post.selftext,
            ""score"": post.score,
            ""created_utc"": post.created_utc,
            ""url"": post.url
        })

# --- Custom Save Folder ---
save_folder = ""/home/robertsory/Documents/RedditData/","This is my guide to developing and expressing an AI policy on your syllabus (regarding both student AI use and your own AI use). I put this under Teaching/Pedagogy rather than Academic Integrity because fundamentally my position is that these policies are much more about the former than the latter. In short, I argue that a professor’s view on AI and academic integrity should flow from their broader pedagogical stance and positions.

I have gotten a great response to it so far, so I figured I would share it here in case anyone is working on their policies at the start of the semester now.

Here is how I describe the guide (it is long so this is as good of a summary as I could muster:

“I recommend that you, the professor, take a holistic approach that addresses both student AI use and your own professorial AI use. This not only creates an equitable culture of honesty and trust but also the opportunity for a dialogue between you and your students about the evolving role of AI in our collective learning experience.

When you develop and refine your student AI use policy, I recommend aligning your views on AI integration, institutional policies, departmental and field standards, and course objectives. I suggest that professors need to consider how students would ideally use AI to achieve their courses’ objectives, before turning to incentivizing students to use AI in those ways (or, perhaps, incentivizing them to not use AI at all). I discuss providing guidelines demarcating responsible AI use from AI misuse, as well as the importance of assessing students' familiarity with AI, ensuring equitable access, and providing AI training opportunities if needed.

Regarding your development of your professorial AI use policy, I advocate you start by clearly defining the scope of your AI use cases in connection with your course, ranging from brainstorming to using personally identifiable student data. I discuss a range of data use strategies, such as restricting AI use to non-student data or obtaining explicit consent when sensitive student data is involved. Throughout, I stress the importance of transparency and flexibility depending on the context.”

I also provide two generic examples of student AI use policies and two generic examples of professorial AI use policies. The examples represent somewhat opposite ends of the “AI openness” spectrum. But they need adjustment to fit real classes.

** Note that you need to subscribe to my newsletter to read it. This was a lot of work so, although I am used to working for free, I decided to make this the one way in which I “charge” for thus work. I hope you will find it is more than worth it (and maybe you will find our other content useful too).",0,1704978634,https://automatedteach.com/p/guide-university-syllabus-ai-policy
Professors,"os.makedirs(save_folder, exist_ok=True)","Greetings all!

Like so many of you, I just wrapped up the fall term at my institution and I just need some colleagues to give me some perspective on what is real right now.  

For this term, I updated my syllabi to include language dedicated to AI misuse after getting caught flatfooted in the Spring by not having such clear policies listed.  I stated a three-tier policy on plagiarism, academic dishonesty, and our writing standard (APA) with a first-level being a warning (generally when students just made a mistake with a citation, etc.), a second-level being a ""zero"" for an assignment (generally when the same students continued to make the same citation errors or when there was a more egregious issue of plagiarism occurring), and a third-level being a ""class failure"" for when students repeatedly plagiarized or used AI at a rate higher than 20% on Turnitin's detector.  

Along the way, I caught \~10 students through the detection system and 7 of them confessed to using it when presented with the evidence.  Two others said they were unaware that using Grammarly to essentially write their papers was considered a violation and another just decided to fight everything (despite very obvious evidence on multiple assignments).  

My institution responded by having the VP issue a statement that essentially told us to stop using AI detection as a means of supplying evidence in order to ""balance"" the needs of academic integrity with fairness towards students.  This letter seemed to run counter to our state's laws which clearly state all grade penalties are to be assessed by the faculty member as noted below: 

*The class instructor is responsible for handling each case of academic dishonesty in the*  
*classroom and for determining a penalty grade as outlined in the course syllabus.*

*If, within the instructor’s professional judgement, reasonable evidence would suggest a student*  
*engaged in academic dishonesty, the instructor will provide notice to the student, either written*  
*or verbal, of their assertion of academic dishonesty and of the academic penalty grade within*  
*thirty instructional days of the occurrence or when the instructor is made aware of the*  
*occurrence.*

*The instructor will submit a report of the assertion of academic dishonesty, the explanation of*  
*the notice or actual notice given to the student and a copy of all applicable evidence to the*  
*Student Conduct Officer (SCO). At this time, the instructor can request that the incident only be*  
*documented with the SCO unofficially, or they can officially refer the matter for disciplinary*  
*action. If the student has a previous academic dishonesty record, then the SCO can choose to*  
*move forward with the disciplinary process without an official referral.* 

The faculty union drafted a letter asking for the VP's letter be rescinded based upon this language to no avail.  Since that point in time, finals have occurred and students seem far more emboldened to cheat while it feels increasingly more like our hands are tied.  

On a personal level, this is taking a massive toll on me mentally and emotionally.  It's hard to stay as engaged and involved in my class discussions, student projects, and maintain my optimistic and positive outlook on my program and my school when I feel repeatedly unsupported and rejected by the institution.  I'm losing sleep, feeling a sense of dread, and am becoming so frustrated with all of this.  I recognize that I'm not alone in this and this is hardly a ""unique to me"" circumstance, but I also have a really difficult time when others essentially won't hold the line with me and seem to be consistently undercutting me for taking a principled stand on academic integrity.  

I'm now on break and I just want to completely disconnect.  At the same time, I've never felt that way before in my 16+ years of teaching.  I've always taken my evaluations and final results and immediately gotten excited about tweaks to make to my classes for the next term.  I've always had a positive outlook on academia and felt a sense of belonging (even when I previously lost jobs due to budget cuts while on the tenure track).  Now, I feel isolated, alone, and unsteady.  I don't know what to do.  Am I going crazy or do I simply just care too much?  Should I just ""let it go"" and let the proverbial criminals run free? Do I double down on this fight? What do I do? What do WE, as faculty, do? 

Thanks to anyone who can give me some moral support, sound judgment, or profound wisdom at this time!",7,1702501556,https://www.reddit.com/r/Professors/comments/18hr6m8/ai_college_support_and_my_mental_health/
Professors,A Guide: How Professors Can Discourage and Prevent AI Misuse,"In this guide, I tried to bring together the core of what we at AutomatED have learned over the past six months into a single summary piece about professors’ optionspace as they design assignments to discourage and prevent AI misuse. I am often told by professors that they would appreciate a zoomed-out take on this issue, rather than a piecemeal or partial approach that discusses only one or two options. Here it is.

I discuss six broad strategies professors can take to discourage and prevent AI misuse by students on a given assignment:

1. Motivate students to not misuse AI in completing the assignment.

2. Require students to complete the assignment without access to AI.

Because AI can be accessed easily on a device connected to the internet — and even on those that are not — this leaves two device-free options:

- Develop an in-class handwritten version of the assignment.

- Develop an in-class oral version of the assignment.

However, in some contexts, secure online proctoring is available as an alternative.

3. Allow students to complete a (more) AI-immune version of the assignment with access to AI.

Developing an assignment to be more AI-immune is a complex and ever-evolving process, but there are two broad categories of options:

- Develop an assignment that is AI-immune due to its format.

- Develop an assignment that is AI-immune due to its content.

4. Pair the assignment with another assignment that students must complete in an AI-free zone, such that they are incentivized to achieve the learning objectives in both cases.

Conceptualize pairing like you conceptualize students’ ability to rely on their peers’ expertise at their dorms and in the dining hall. Sure, they can ask their clever friend about how to solve a problem or write an essay, but then they need to come to class and perform with those skills and that knowledge internalized (and not merely memorized).

5. Do nothing.

6. Some combination of the above.


In short, I recommend #6. Check it out and let me know what you think. (Be aware that it is somewhat long.)",3,1691406049,https://automated.beehiiv.com/p/guide-professors-discourage-prevent-ai-misuse
,# --- Save to CSV ---,,,,
,"save_path = os.path.join(save_folder, ""AI_lazy_claim_reddit_posts.csv"")",,,,
,df = pd.DataFrame(posts_data),,,,
,"df.to_csv(""/mnt/data/edu_ai_ethics_subreddits.csv"", index=False)",,,,
,,,,,
,"print(f""✅ Done! Saved to {save_path}"")",,,,
